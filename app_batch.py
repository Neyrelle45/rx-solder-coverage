import streamlit as st
import cv2
import numpy as np
import pandas as pd
import joblib
import io
import zipfile
import analyse_rx_soudure as engine

st.set_page_config(page_title="RX Expert - Batch Precision", layout="wide")

if 'batch_history' not in st.session_state:
    st.session_state.batch_history = []

# --- STYLE DU TABLEAU (Colonnes indÃ©pendantes) ---
def apply_table_style(df):
    # Applique le rouge sur le max de Total_% ET le bleu sur le max de Void_Max_%
    return df.style.highlight_max(subset=['Total_%'], color='#ffcccc', axis=0) \
                   .highlight_max(subset=['Void_Max_%'], color='#cce5ff', axis=0)

st.title("ğŸ“¦ Analyse de SÃ©rie - Haute VisibilitÃ©")

# --- CONFIGURATION ---
st.sidebar.title("âš™ï¸ ParamÃ¨tres")
model_file = st.sidebar.file_uploader("1. ModÃ¨le IA", type=["joblib"])
# Note : Vous avez trouvÃ© qu'augmenter le contraste aidait, je laisse le slider ici
contrast_val = st.sidebar.slider("2. Contraste (RÃ©glage critique)", 0.0, 10.0, 2.0, 0.1)

st.sidebar.divider()
st.sidebar.subheader("ğŸ•¹ï¸ Alignement Fixe")
tx = st.sidebar.number_input("Translation X", value=0)
ty = st.sidebar.number_input("Translation Y", value=0)
rot = st.sidebar.slider("Rotation (Â°)", -180.0, 180.0, 0.0)
sc = st.sidebar.slider("Ã‰chelle", 0.8, 1.2, 1.0)

if st.sidebar.button("ğŸ—‘ï¸ Vider les rÃ©sultats"):
    st.session_state.batch_history = []
    st.rerun()

# --- CHARGEMENT ---
col_u, col_m = st.columns(2)
with col_u:
    uploaded_rx = st.file_uploader("Images RX", type=["png", "jpg", "jpeg", "tif"], accept_multiple_files=True)
with col_m:
    mask_file = st.file_uploader("Masque de rÃ©fÃ©rence", type=["png", "jpg"])

st.divider()
trigger = st.button("ğŸš€ Lancer l'analyse batch", use_container_width=True, type="primary")

if trigger and model_file and uploaded_rx and mask_file:
    clf = joblib.load(model_file)
    st.session_state.batch_history = [] 
    
    # 1. Masque MaÃ®tre
    m_raw = cv2.imdecode(np.frombuffer(mask_file.read(), np.uint8), cv2.IMREAD_COLOR)
    m_rgb = cv2.cvtColor(m_raw, cv2.COLOR_BGR2RGB)
    r_s, g_s, b_s = cv2.split(m_rgb)
    m_green = (g_s > 100).astype(np.uint8)
    # SensibilitÃ© des vias : on capture tout ce qui est sombre dans le vert
    m_black = ((r_s < 100) & (g_s < 100) & (b_s < 100) & (m_green > 0)).astype(np.uint8)

    progress = st.progress(0)
    
    for idx, rx_f in enumerate(uploaded_rx):
        # 2. Image RX
        img_gray = engine.load_gray(rx_f, contrast_limit=contrast_val)
        H, W = img_gray.shape
        
        # 3. Alignement identique Ã  app.py
        M = engine.compose_similarity(sc, rot, float(tx), float(ty), W/2, H/2)
        env_adj = cv2.warpAffine(cv2.resize(m_green, (W, H), interpolation=cv2.INTER_NEAREST), M, (W, H), flags=cv2.INTER_NEAREST)
        hol_adj = cv2.warpAffine(cv2.resize(m_black, (W, H), interpolation=cv2.INTER_NEAREST), M, (W, H), flags=cv2.INTER_NEAREST)
        
        z_utile = (env_adj > 0) & (hol_adj == 0)
        area_ref = np.sum(z_utile)

        # 4. IA
        feats = engine.compute_features(img_gray)
        raw_pred = np.argmax(clf.predict_proba(feats.reshape(-1, feats.shape[-1])), axis=1).reshape(H, W)
        
        # ForÃ§age IA dans la zone utile
        final_pred = np.ones((H, W), dtype=np.uint8)
        final_pred[z_utile] = raw_pred[z_utile]

        # 5. Calcul des manques
        mask_red_raw = (final_pred == 0) & z_utile
        cnts, _ = cv2.findContours(mask_red_raw.astype(np.uint8)*255, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        mask_red = np.zeros((H, W), dtype=bool)
        for c in cnts:
            if area_ref > 0 and (cv2.contourArea(c) / area_ref * 100) >= 0.1:
                cv2.drawContours(mask_red.view(np.uint8), [c], -1, 1, -1)

        # 6. Macro-void (Cyan) avec test de collision strict
        v_max_area, v_max_poly = 0, None
        red_cnts, _ = cv2.findContours(mask_red.astype(np.uint8)*255, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for rc in red_cnts:
            area = cv2.contourArea(rc)
            t_m = np.zeros((H, W), dtype=np.uint8)
            cv2.drawContours(t_m, [rc], -1, 255, 2)
            if not np.any((t_m > 0) & (hol_adj > 0)) and not np.any((t_m > 0) & (env_adj == 0)):
                if area > v_max_area:
                    v_max_area, v_max_poly = area, rc

        # 7. RENDU FINAL (PrioritÃ© visibilitÃ© Vias)
        res_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)
        
        # CrÃ©ation du calque de couleur
        overlay = res_rgb.copy()
        overlay[z_utile & (~mask_red)] = [255, 255, 0] # Jaune
        overlay[mask_red] = [255, 0, 0]                # Rouge
        
        # Application de l'overlay uniquement lÃ  oÃ¹ il n'y a PAS de via
        # Cela garantit que les vias sont l'image originale pure
        mask_final = (env_adj > 0) & (hol_adj == 0)
        res_rgb[mask_final] = overlay[mask_final]
        
        if v_max_poly is not None:
            cv2.drawContours(res_rgb, [v_max_poly], -1, [0, 255, 255], 2)

        # 8. Sauvegarde
        _, enc = cv2.imencode(".jpg", cv2.cvtColor(res_rgb, cv2.COLOR_RGB2BGR), [int(cv2.IMWRITE_JPEG_QUALITY), 95])
        st.session_state.batch_history.append({
            "Fichier": rx_f.name,
            "Total_%": round((np.sum(mask_red)/area_ref*100), 2) if area_ref > 0 else 0,
            "Void_Max_%": round((v_max_area/area_ref*100), 3) if area_ref > 0 else 0,
            "img_bytes": enc.tobytes()
        })
        progress.progress((idx + 1) / len(uploaded_rx))

# --- AFFICHAGE ---
if st.session_state.batch_history:
    df = pd.DataFrame(st.session_state.batch_history)
    st.subheader("ğŸ“Š Statistiques de la sÃ©rie")
    # Application du nouveau style indÃ©pendant
    st.dataframe(apply_table_style(df.drop(columns=['img_bytes'])), use_container_width=True)
    
    with st.expander("ğŸ‘ï¸ Galerie des rÃ©sultats", expanded=True):
        grid = st.columns(4)
        for i, item in enumerate(st.session_state.batch_history):
            grid[i % 4].image(item['img_bytes'], caption=item['Fichier'])
